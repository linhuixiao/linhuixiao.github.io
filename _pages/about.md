---
permalink: /
title: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---


My Chinese Name is 肖麟慧. I'm currently a Research Assistant Professor at Pengcheng Laboratory. I obtained my Ph.D. degree from the National Key Laboratory of Multimodal Artificial Intelligence Systems at the Institute of Automation, Chinese Academy of Sciences. My doctoral advisors were [Prof. Changsheng Xu](https://scholar.google.com.hk/citations?user=hI9NRDkAAAAJ&hl=zh-CN) and [Prof. Xiaoshan Yang](https://yangxs.ac.cn/home). During the doctoral period, I entered Pengcheng Laboratory for joint cultivation under the guidance of [Prof. Yaowei Wang](https://scholar.google.com.hk/citations?user=o_DllmIAAAAJ&hl=zh-CN) and [Prof. Lan Xiangyuan](https://scholar.google.com.hk/citations?user=c3iwWRcAAAAJ&hl=zh-CN). I obtained my Master's degree from the State Key Laboratory of Transducer Technology, Chinese Academy of Sciences, where my advisor was [Prof. Xudong Zou](https://scholar.google.com.hk/citations?user=Fku_O9IAAAAJ&hl=zh-CN). I have long focused on the research of key technologies in artificial intelligence and visual grounding, publishing a series of influential research works in top international journals and conferences on artificial intelligence (e.g., NeurIPS, TPAMI, ACM MM, TMM, TNNLS, RAS, etc.). One of the papers was included in ESI's global top 1% highly cited papers. As the first inventor or student first inventor, I have accumulated over 15 Chinese and international invention patents (including 12 authorized Chinese patents and two international patents), and served as a reviewer for more than 10 top international journals and conferences in the field of artificial intelligence. My current research focuses on artificial intelligence, multimodal learning, multimodal visual grounding, and 3D visual localization. I am dedicated to developing efficient and generalizable algorithms to address real-world visual understanding tasks and promote the widespread application of machine intelligence.

I always maintain an open and collaborative academic attitude. Colleagues who are interested in my research work are welcome to engage in discussions, and **scholars and students with potential collaboration interests are also encouraged to pursue in-depth cooperation with me**. If interested, please feel free to contact me via email.

Furthermore, the Institute of Perception at Pengcheng National Laboratory consistently undertakes multiple major national research initiatives related to visual perception. Students interested in applying for [joint Ph.D programs](https://yzw.pcl.ac.cn/home) are also welcome to reach out via email for consultation and exchange.


Education Background
======
* 2021—2025  Ph.D.，[University of Chinese Academy of Sciences (UCAS)](https://www.ucas.edu.cn/)
  * Institute of Automation, Chinese Academy of Sciences, National Key Laboratory of Multimodal Artificial Intelligence Systems, Beijing, China
  * Pengcheng Laboratory, Shenzhen, China
  * UCAS ranks No. 1 in China in the ESI ranking system and No. 69 globally in the [US News ranking system](https://www.usnews.com/education/best-global-universities/rankings).
* 2016—2019  Master，[University of Chinese Academy of Sciences (UCAS)](https://www.ucas.edu.cn/)
  * Institute of Aerospace Information, Chinese Academy of Sciences, State Key Laboratory of Transducer Technology, Beijing, China
* 2012—2016  Bachelor，[Nanchang University](https://www.ncu.edu.cn/)
  * Nanchang University, Department of Physics, Nanchang, China


Selected Publications
======
* **Linhui Xiao**, Xiaoshan Yang, Fang Peng, Yaowei Wang, Changsheng Xu. "OneRef: Unified One-tower Expression Grounding and Segmentation with Mask Referring Modeling." NeurIPS 2024. CCF-A top conference. [Download Paper](https://openreview.net/pdf?id=siPdcro6uD), [Code](https://github.com/linhuixiao/OneRef)
* **Linhui Xiao**, Xiaoshan Yang, Fang Peng, Yaowei Wang, Changsheng Xu. "HiVG: Hierarchical Multimodal Fine-grained Modulation for Visual Grounding." ACM MM 2024. CCF-A top conference. [Download Paper](https://dl.acm.org/doi/pdf/10.1145/3664647.3681071), [Code](https://github.com/linhuixiao/HiVG)
* **Linhui Xiao**, Xiaoshan Yang, Xiangyuan Lan, Yaowei Wang, Changsheng Xu. "Towards Visual Grounding: A Survey." TPAMI 2025. CCF-A/JCR/CAS top journal. [Download Paper](https://arxiv.org/pdf/2412.20206), [Code](https://github.com/linhuixiao/Awesome-Visual-Grounding)
* **Linhui Xiao**, Xiaoshan Yang, Fang Peng, Ming Yan, Yaowei Wang, Changsheng Xu. "CLIP-VG: Self-paced Curriculum Adapting of CLIP for Visual Grounding." TMM 2023. JCR/CAS top journal. [Download Paper](https://arxiv.org/pdf/2305.08685), [Code](https://github.com/linhuixiao/CLIP-VG)
* **Linhui Xiao**, Jinge wang, Zhen Rong, Xudong Zou. "Dynamic-SLAM: Semantic monocular visual localization and mapping based on deep learning in dynamic environment." RAS. JCR top journal. ESI top 1% highly cited papers globally. [Download Paper](https://www.researchgate.net/profile/Linhui-Xiao/publication/332149941_Dynamic-SLAM_Semantic_monocular_visual_localization_and_mapping_based_on_deep_learning_in_dynamic_environment/links/6013f1fa45851517ef22eb7d/Dynamic-SLAM-Semantic-monocular-visual-localization-and-mapping-based-on-deep-learning-in-dynamic-environment.pdf), [Code](https://github.com/linhuixiao/Dynamic-SLAM)
* Fang Peng, Xiaoshan Yang, **Linhui Xiao**, Yaowei Wang, Changsheng Xu. "SgVA-CLIP: Semantic-Guided Visual Adapting of Vision-Language Models for Few-Shot Image Classification." TMM 2023. JCR/CAS top journal. [Download Paper](https://arxiv.org/pdf/2211.16191), [Code](https://github.com/FannierPeng/SgVA-CLIP)
* Yabo Liu, Jinghua Wang, **Linhui Xiao**, Chengliang Liu, Zhihao Wu, Yong Xu "Foregroundness-Aware Task Disentanglement and Self-Paced Curriculum Learning for Domain Adaptive Object Detection." TNNLS 2023. JCR/CAS top journal. [Download Paper](https://ieeexplore.ieee.org/abstract/document/10329584)

For more publications, please refer to [my Google Scholar homepage](https://scholar.google.com.hk/citations?user=4rTE4ogAAAAJ&hl=zh-CN&oi=ao)


Selected Patents
======
* “Data Processing Device, Data Processing Method, And Related Product.” International patent. No. WO 2023/045445 A1. First inventor. [Download patent](https://patents.google.com/patent/WO2023045445A1/en?oq=WO2023045445A1)
* “Computing Apparatus, Data Processing Method, And Related Product.” International patent. No. WO 2023/045446A1. First inventor. [Download patent](https://patents.google.com/patent/WO2023045446A1/en?oq=WO2023045446A1)

  
Selected Awards & Honors
======
* 2025 Outstanding Ph.D. Graduate of Beijing
* 2025 Outstanding Ph.D. Graduate of Pengcheng Laboratory
* 2025 Outstanding Ph.D. Graduate of the University of Chinese Academy of Sciences
* 2024 Shenzhen Pengcheng Science and Education Foundation "Director's Scholarship" award (Top 2%, the highest honor for the doctoral students in PCL)
* 2024 First Prize of the Pandeng Scholarship, UCAS
* 2023 Shenzhen Pengcheng Science and Education Foundation "Talent Development Scholarship" award (Top 5%)
* 2019 and 2024 "Merit Student" of the University of Chinese Academy of Sciences
* 2018 IEEE International Conference on Robotics and Control Engineering (IRCE), Best Oral Presentation Award and Best Poster Award, [News](https://www.irce.org/2018.html)
* 2016 Outstanding Undergraduate Graduates of Nanchang University (only the top 5% of graduates won this honor)
* 2015 Mathematical Contest in Modeling for American College Students, International First Prize. (Top 8%, [News 1](http://m.ncu.edu.cn/ndyw/9951640e58f24ea59a6427e50aa2eaa3.htm)，[News 2](https://jwc.ncu.edu.cn/xwdt/20485.htm))
* From 2012 to 2016, I received various scholarships and honorary titles from Nanchang University (such as the "First-class Academic Scholarship", "Yang Yigen Scholarship", "National Scholarship", "Merit Student", "Star of Science", etc.) on more than 20 occasions.


Academic Services
======

**Conference Reviewer**

* ICML 2025
* NeurIPS 2024, 2025
* ICLR 2024, 2025, 2026
* ECCV 2024, 2025
* CVPR 2024
* ACM MM 2023、2024, 2025
* AAAI 2023、2024、2025, 2026
* IROS 2019、2020、2021、2022、2023

**Journal Reviewer**
 
* IEEE Transactions on Multimedia (TMM)
* IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)
* IEEE Robotics and Automation Letters (RA-L)
* Pattern Recognition (PR)
* Information Fusion (IF)
* NeurComputing
* etc.


Contact
======
* Email: [xiaolinhui16@mails.ucas.ac.cn](xiaolinhui16@mails.ucas.ac.cn)


Global Visiting Map
======

<a href="https://clustrmaps.com/site/1c5bs"  title="ClustrMaps"><img src="//www.clustrmaps.com/map_v2.png?d=6mewWzwVl4RKOGXq_GLS_8L3emLk_99zRKyVv29Gaso&cl=ffffff" /></a>


